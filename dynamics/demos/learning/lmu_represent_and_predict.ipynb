{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing and Predicting SSP Dynamics using LMUs\n",
    "\n",
    "We use an environment of a ball bouncing around a frictionless surface without loss in kinematic energy to create a time-series of SSPs which are then used to drive a high-dimensional LMU.\n",
    "\n",
    "A two-layer MLP is used to learn $f : X \\mapsto X$ where $X$ is the state of the LMU, the domain corresponds to the current history, and the range corresponds to the history fast-forwarded by 1.5 windows. In other words, the neural network learns to predict the representation of future trajectories. \n",
    "\n",
    "We also use the grid / place cell representation from \"Accurate representation for spatial cognition using grid cells\" (Nicole Sandra-Yaffa Dumont & Chris Eliasmith, 2020) to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import cont2discrete\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import nengo\n",
    "import nengo_spa as spa\n",
    "from ssp.collisions import Simulation\n",
    "from ssp.maps import Spatial2D\n",
    "from ssp.plots import heatmap_animation, create_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: refactor common code with benchmarking and predicting_collision_dynamics into ssp/collisions.py\n",
    "\n",
    "grid_size = 5  # in units of circle's diameter\n",
    "n_particles = 1\n",
    "radii = np.ones(n_particles) / grid_size / 2\n",
    "dt = 0.4\n",
    "frames = 500\n",
    "interval = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulation(n_particles, radius=radii, rng=np.random.RandomState(seed=0))\n",
    "ani = sim.do_animation(dt=dt, frames=frames, interval=interval)\n",
    "HTML('<img src=\"data:image/gif;base64,{0}\" />'.format(create_gif(ani, fname=\"environment.gif\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaoted from ssp_grid_cell_utils.py and ssp_grid_cell_examples.ipynb\n",
    "# Accurate representation for spatial cognition using grid cells\n",
    "# Nicole Sandra-Yaffa Dumont & Chris Eliasmith\n",
    "\n",
    "def ssp_plane_basis(K):\n",
    "    # Create the bases vectors X,Y as described in the paper with the wavevectors \n",
    "    # (k_i = (u_i,v_i)) given in a matrix K. To get hexganal patterns use 3 K vectors 120 degs apart\n",
    "    # To get mulit-scales/orientation, give many such sets of 3 K vectors \n",
    "    # K is _ by 2 \n",
    "    d = K.shape[0]\n",
    "    FX = np.ones((d*2 + 1,), dtype=\"complex\")\n",
    "    FX[0:d] = np.exp(1.j*K[:,0])\n",
    "    FX[-d:] = np.flip(np.conj(FX[0:d]))\n",
    "    FX = np.fft.ifftshift(FX)\n",
    "    FY = np.ones((d*2 + 1,), dtype=\"complex\")\n",
    "    FY[0:d] = np.exp(1.j*K[:,1])\n",
    "    FY[-d:] = np.flip(np.conj(FY[0:d]))\n",
    "    FY = np.fft.ifftshift(FY)\n",
    "    \n",
    "    X = spa.SemanticPointer(data=np.fft.ifft(FX))\n",
    "    Y = spa.SemanticPointer(data=np.fft.ifft(FY))\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def generate_grid_cell_basis(n_scales, n_rotates, scale_min=0.5, scale_max=1.8):\n",
    "    \"\"\"Generates basis vectors with ``d = n_scales * n_rotates * 6 + 1``.\"\"\"\n",
    "    K_hex = np.array(\n",
    "        [[0, 1],\n",
    "         [np.sqrt(3) / 2, -0.5],\n",
    "         [-np.sqrt(3) / 2, -0.5]]\n",
    "    )\n",
    "\n",
    "    # Combining multiple n_scales sets of 3 wave vectors that give hexagonal grid interference patterns\n",
    "    # each set of 3 giving a different grid resolution\n",
    "    scales = np.linspace(scale_min, scale_max, n_scales)\n",
    "    K_scales = np.vstack([K_hex * i for i in scales])\n",
    "\n",
    "    # Combining multiple n_rotates sets of 3 wave vectors that give hexagonal grid interference patterns\n",
    "    # each set of 3 giving a different grid orientation\n",
    "    thetas = np.arange(0, n_rotates) * np.pi / (3 * n_rotates)\n",
    "    R_mats = np.stack([np.stack([np.cos(thetas), -np.sin(thetas)], axis=1),\n",
    "                       np.stack([np.sin(thetas), np.cos(thetas)], axis=1)],\n",
    "                      axis=1)\n",
    "    # TODO: don't double transpose\n",
    "    K_rotates = (R_mats @ K_hex.T).transpose(1, 2, 0).T.reshape(-1, 2)\n",
    "\n",
    "    # Multiple resolutions and orientations\n",
    "    # TODO: don't double transpose\n",
    "    K_scale_rotates = (R_mats @ K_scales.T).transpose(1, 2, 0).T.reshape(-1, 2)\n",
    "\n",
    "    # Generate the (X, Y) basis vectors\n",
    "    X, Y = ssp_plane_basis(K_scale_rotates)\n",
    "    d = n_scales * n_rotates * 6 + 1\n",
    "    assert len(X) == len(Y) == d\n",
    "    return X, Y, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points in the simulation are within [0, 1]^2 and then visualized\n",
    "# on [-0.5, 0.5]^2 with a scale of sqrt(2)*grid_size such\n",
    "# that the diameter of each ball is roughly the same scale\n",
    "\n",
    "ssp_radius = np.sqrt(2)  # open problem: deriving this\n",
    "ssp_scale = ssp_radius * grid_size\n",
    "\n",
    "X, Y, d = generate_grid_cell_basis(n_scales=10, n_rotates=9,\n",
    "                                   scale_min=0.9, scale_max=3.5)\n",
    "dim = d\n",
    "print(\"Dimensionality:\", d)\n",
    "\n",
    "ssp_map = Spatial2D(dim=dim, scale=ssp_scale, X=X, Y=Y, rng=np.random.RandomState(seed=0))\n",
    "\n",
    "ssp_map.build_grid(x_len=1, y_len=1, x_spaces=101, y_spaces=101)\n",
    "\n",
    "names = string.ascii_uppercase[:n_particles]\n",
    "assert len(names) == n_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LMU system from Voelker et al., 2019\n",
    "# https://www.nengo.ai/nengo-dl/examples/lmu.html\n",
    "\n",
    "order = 12\n",
    "theta = 10  # in discrete time-steps\n",
    "\n",
    "Q = np.arange(order, dtype=np.float64)\n",
    "R = (2 * Q + 1)[:, None] / theta\n",
    "j, i = np.meshgrid(Q, Q)\n",
    "\n",
    "A = np.where(i < j, -1, (-1.0) ** (i - j + 1)) * R\n",
    "B = (-1.0) ** Q[:, None] * R\n",
    "C = np.ones((1, order))\n",
    "D = np.zeros((1,))\n",
    "\n",
    "A, B, _, _, _ = cont2discrete((A, B, C, D), dt=1.0, method=\"zoh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lmu_data(n_seeds, n_frames_per_seed, start_seed=0):\n",
    "    states = np.zeros((n_seeds, n_frames_per_seed, order, ssp_map.voc.dimensions))\n",
    "    zero = np.zeros((order, ssp_map.voc.dimensions))\n",
    "    \n",
    "    for seed in range(n_seeds):\n",
    "        sim = Simulation(\n",
    "            n_particles,\n",
    "            radius=radii,\n",
    "            rng=np.random.RandomState(seed=seed + start_seed),\n",
    "        )\n",
    "\n",
    "        for step in range(n_frames_per_seed):\n",
    "            ssp = ssp_map.encode_points(sim.x, sim.y, names)\n",
    "\n",
    "            last_state = states[seed, step-1, :, :] if step else zero\n",
    "            states[seed, step, :, :] = A.dot(last_state) + B * ssp.v\n",
    "\n",
    "            sim.advance(dt)\n",
    "\n",
    "    return states\n",
    "\n",
    "states = generate_lmu_data(n_seeds=100, n_frames_per_seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Legendre basis to read out the state of the LMU to see what\n",
    "# it is representing (purely for visualization)\n",
    "\n",
    "n_visualize = 5  # number of samples in history to visualize\n",
    "\n",
    "from scipy.special import legendre\n",
    "t = np.linspace(0, 1, n_visualize)\n",
    "basis = np.asarray([legendre(i)(2*t - 1) for i in range(order)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the history training data\n",
    "# Everything will be done in the Legendre space, but it is still helpful\n",
    "# to see what it is representing along a number of samples in the window\n",
    "\n",
    "heatmaps = []\n",
    "for step in range(frames):\n",
    "    # Add together all the points in the history \n",
    "    state = states[step // states.shape[1], step % states.shape[1]]\n",
    "    history = spa.SemanticPointer(\n",
    "        np.sum(basis.T.dot(state), axis=0))\n",
    "\n",
    "    heatmaps.append(\n",
    "        ssp_map.compute_heatmap(history, names=names)\n",
    "    )\n",
    "\n",
    "ani = heatmap_animation([heatmaps], figsize=(4, 4), interval=interval,\n",
    "                        titles=['Training Data (Subset)'])\n",
    "HTML('<img src=\"data:image/gif;base64,{0}\" />'.format(create_gif(ani, fname=\"ssphist.gif\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver = nengo.solvers.LstsqL2(reg=1e-3)\n",
    "\n",
    "predict_steps = 15\n",
    "\n",
    "shape_flat = (states.shape[0] * (states.shape[1] - predict_steps),\n",
    "              states.shape[2] * states.shape[3])\n",
    "\n",
    "train_input = states[:, :-predict_steps].reshape(shape_flat)\n",
    "train_output = states[:, predict_steps:].reshape(shape_flat)\n",
    "\n",
    "#D, _ = solver(train_input, train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssp.models import MLP\n",
    "\n",
    "mlp = MLP(order * ssp_map.voc.dimensions, [1024, 1024], order * ssp_map.voc.dimensions)\n",
    "mlp.train(train_input, train_output, n_steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start seed for test data must be greater than n_seeds used for training data\n",
    "states = generate_lmu_data(\n",
    "    n_seeds=1, n_frames_per_seed=frames, start_seed=9000).squeeze(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first axis is squeezed (n_seeds=1) and so len(states) == frames\n",
    "assert len(states) == frames\n",
    "\n",
    "# Use D to predict future windows\n",
    "states_flat = states.reshape((len(states), -1))\n",
    "\n",
    "#pred_states = states_flat.dot(D).reshape((len(states), order, ssp_map.voc.dimensions))\n",
    "pred_states = np.asarray(mlp(states_flat)).reshape((len(states), order, ssp_map.voc.dimensions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 1, 5)\n",
    "# t = np.asarray([0.5])  # predict the middle of the window\n",
    "pred_basis = np.asarray([legendre(i)(2*t - 1) for i in range(order)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it together to visualize the history along with predictions and ground truth\n",
    "heatmaps = []\n",
    "\n",
    "for step in range(frames - predict_steps):\n",
    "    # Add together all the points in the history \n",
    "    history = spa.SemanticPointer(\n",
    "        np.sum(basis.T.dot(states[step]), axis=0))\n",
    "\n",
    "    # Add together all the points in the prediction \n",
    "    pred = spa.SemanticPointer(\n",
    "        np.sum(pred_basis.T.dot(pred_states[step]), axis=0))\n",
    "\n",
    "    # Add together all the points in the future \n",
    "    future = spa.SemanticPointer(\n",
    "        np.sum(pred_basis.T.dot(states[step + predict_steps]), axis=0))\n",
    "\n",
    "    # Show all three separately\n",
    "    heatmaps.append(\n",
    "        [ssp_map.compute_heatmap(history + pred, names=names),\n",
    "         ssp_map.compute_heatmap(history + future, names=names),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "ani = heatmap_animation(list(zip(*heatmaps)), figsize=(8, 4), interval=interval,\n",
    "                        titles=['History + Prediction', 'History + Actual Future'])\n",
    "HTML('<img src=\"data:image/gif;base64,{0}\" />'.format(create_gif(ani, fname=\"ssppred.gif\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LPS Part3",
   "language": "python",
   "name": "lps-part3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
